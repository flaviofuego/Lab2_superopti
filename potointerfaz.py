import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score

# Configuraci贸n de la p谩gina
st.set_page_config(
    page_title="Laboratorio 2: Algoritmos de Optimizaci贸n en ML",
    page_icon="",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos personalizados
st.markdown("""
<style>
    .title {
        text-align: center;
        font-weight: bold;
        color: #3366ff;
    }
    .subtitle {
        font-weight: bold;
        color: #0099cc;
    }
    .centered {
        display: flex;
        justify-content: center;
    }
    .metric-card {
        background-color: #f8f9fa;
        border-radius: 5px;
        padding: 10px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.1);
    }
    .caption {
        font-size: 0.85em;
        color: #666;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# T铆tulo principal
st.markdown("<h1 class='title'>Laboratorio 2: Algoritmos de Optimizaci贸n en Machine Learning</h1>", unsafe_allow_html=True)
st.markdown("### An谩lisis del rendimiento acad茅mico de estudiantes")

# Funci贸n para cargar datos
@st.cache_data
def load_data():
    try:
        data = pd.read_csv('Student_Performance.csv')
        return data
    except FileNotFoundError:
        st.error("No se encontr贸 el archivo 'Student_Performance.csv'. Por favor, aseg煤rese de que el archivo est茅 en el mismo directorio que esta aplicaci贸n.")
        return None

# Barra lateral para navegaci贸n
st.sidebar.title("Navegaci贸n")
pages = st.sidebar.radio("Ir a:", [
    "1. Descripci贸n del Dataset",
    "2. An谩lisis Exploratorio",
    "3. Visualizaci贸n 3D",
    "4. Modelado y Optimizaci贸n",
    "5. M茅tricas y Evaluaci贸n",
    "6. Conclusiones"
])

# Cargar el dataset
data = load_data()

if data is not None:
    # 1. DESCRIPCIN DEL DATASET
    if pages == "1. Descripci贸n del Dataset":
        st.markdown("<h2 class='subtitle'>1. Descripci贸n del Dataset</h2>", unsafe_allow_html=True)
        
        # Informaci贸n general
        col1, col2 = st.columns(2)
        with col1:
            st.metric("N煤mero de muestras", data.shape[0])
        with col2:
            st.metric("N煤mero de variables", data.shape[1])
        
        # Primeras filas
        st.subheader("Primeras filas del dataset")
        st.dataframe(data.head())
        
        # Estad铆sticas descriptivas
        st.subheader("Estad铆sticas descriptivas")
        st.dataframe(data.describe())
        
        
        def formato_tipo_dato(tipo):
            """Convierte tipos de datos t茅cnicos a t茅rminos m谩s comprensibles en espa帽ol"""
            if 'int' in str(tipo):
                return "entero"
            elif 'float' in str(tipo):
                return "decimal"
            elif 'object' in str(tipo):
                return "categ贸rico"
            elif 'bool' in str(tipo):
                return "booleano"
            elif 'datetime' in str(tipo):
                return "fecha/hora"
            else:
                return str(tipo)
        # Informaci贸n sobre los tipos de datos
        st.subheader("Informaci贸n sobre tipos de datos")
        
        # Crea una tabla personalizada para mostrar la informaci贸n
        info_datos = []
        for col in data.columns:
            no_nulos = data[col].count() # Cuenta valores no-nulo
            tipo = formato_tipo_dato(data[col].dtype) # Obtiene el tipo de dato y lo formatea
            porcentaje = 100 * (no_nulos / len(data)) # Porcentaje de completitud
            
            info_datos.append({
                "Columna": col,
                "Tipo de Dato": tipo,
                "Valores No-Nulos": f"{no_nulos} de {len(data)} ({porcentaje:.1f}%)"
            })

        # Convierte a DataFrame para mostrar como tabla
        info_df = pd.DataFrame(info_datos)
        st.table(info_df)

        # Informaci贸n adicional del dataset
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**N煤mero de filas:** {data.shape[0]}")
            st.write(f"**N煤mero de columnas:** {data.shape[1]}")

        with col2:
            memo_kb = data.memory_usage(deep=True).sum() / 1024
            st.write(f"**Uso de memoria:** {memo_kb:.1f} KB")
        
        # Valores 煤nicos en variables categ贸ricas
        st.subheader("Valores 煤nicos en Extracurricular Activities")
        st.write(data['Extracurricular Activities'].unique())
        
        # Valores nulos
        st.subheader("Valores nulos en el dataset")
        st.write(data.isnull().sum())
        
        # Descripci贸n de las variables
        st.subheader("Descripci贸n de las variables")
        
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("<h4>Variables independientes (predictores)</h4>", unsafe_allow_html=True)
            st.markdown("- **Hours Studied**: Horas dedicadas al estudio")
            st.markdown("- **Previous Scores**: Calificaciones previas")
            st.markdown("- **Extracurricular Activities**: Participaci贸n en actividades extracurriculares (categ贸rica)")
            st.markdown("- **Sleep Hours**: Horas de sue帽o")
            st.markdown("- **Sample Question Papers Practiced**: N煤mero de ex谩menes de pr谩ctica realizados")
        
        with col2:
            st.markdown("<h4>Variable dependiente</h4>", unsafe_allow_html=True)
            st.markdown("- **Performance Index**: ndice de rendimiento acad茅mico")
    
    # 2. ANLISIS EXPLORATORIO
    elif pages == "2. An谩lisis Exploratorio":
        st.markdown("<h2 class='subtitle'>2. An谩lisis Exploratorio de Datos</h2>", unsafe_allow_html=True)
        
        # Selecci贸n de caracter铆sticas para visualizaci贸n
        st.subheader("Visualizaci贸n de relaciones entre variables")
        
        features_options = ['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced']
        selected_features = st.multiselect(
            "Seleccione caracter铆sticas para analizar (m谩ximo 3):",
            features_options,
            default=['Hours Studied', 'Previous Scores', 'Sleep Hours'],
            max_selections=3
        )
        
        if len(selected_features) > 0:
            # Matriz de correlaci贸n
            selected_features_with_target = selected_features + ['Performance Index']
            correlation_matrix = data[selected_features_with_target].corr()
            
            st.subheader("Matriz de Correlaci贸n")
            fig_corr = plt.figure(figsize=(10, 8))
            sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
            plt.title('Matriz de Correlaci贸n')
            st.pyplot(fig_corr)
            
            # Interpretaci贸n de correlaciones
            st.subheader("Interpretaci贸n de correlaciones")
            for feature in selected_features:
                corr_value = correlation_matrix.loc[feature, 'Performance Index']
                correlacion = ""

                if abs(corr_value) > 0.7:
                    correlacion = "**Correlaci贸n fuerte**"
                elif abs(corr_value) > 0.3:
                    correlacion = "**Correlaci贸n moderada**"
                else:
                    correlacion = "**Correlaci贸n d茅bil**"

                st.markdown(f"- **{feature} vs. Performance Index**: {corr_value:.4f} ({correlacion})")
            
            # Scatter plots individuales
            st.subheader("Relaciones entre variables seleccionadas y Performance Index")
            
            col1, col2 = st.columns(2)
            
            for i, feature in enumerate(selected_features):
                fig = plt.figure(figsize=(10, 6))
                sns.regplot(x=feature, y='Performance Index', data=data)
                plt.title(f'Relaci贸n entre {feature} y Performance Index')
                plt.xlabel(feature)
                plt.ylabel('Performance Index')
                plt.tight_layout()
                
                if i % 2 == 0:
                    with col1:
                        st.pyplot(fig)
                else:
                    with col2:
                        st.pyplot(fig)
            
            # Distribuci贸n de la variable objetivo
            st.subheader("Distribuci贸n de Performance Index")
            fig_dist = plt.figure(figsize=(10, 6))
            sns.histplot(data['Performance Index'], kde=True)
            plt.title('Distribuci贸n de Performance Index')
            st.pyplot(fig_dist)
            
            # Boxplot para variable categ贸rica
            st.subheader("Performance Index por Tipo de Actividad Extracurricular")
            fig_box = plt.figure(figsize=(10, 6))
            sns.boxplot(x='Extracurricular Activities', y='Performance Index', data=data)
            plt.title('Performance Index por Tipo de Actividad Extracurricular')
            st.pyplot(fig_box)
        else:
            st.warning("Por favor, seleccione al menos una caracter铆stica para visualizar.")
    
    # 3. VISUALIZACIN 3D
    elif pages == "3. Visualizaci贸n 3D":
        st.markdown("<h2 class='subtitle'>3. Visualizaci贸n 3D de Relaciones</h2>", unsafe_allow_html=True)
        
        st.write("Explore c贸mo dos predictores se relacionan con el rendimiento acad茅mico en un espacio tridimensional.")
        
        # Selecci贸n de caracter铆sticas para visualizaci贸n 3D
        col1, col2 = st.columns(2)
        
        with col1:
            feature_x = st.selectbox(
                "Seleccione la primera caracter铆stica (eje X):",
                ['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced'],
                index=1  # Previous Scores por defecto
            )
        
        with col2:
            # Excluimos la caracter铆stica ya seleccionada
            remaining_features = [f for f in ['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced'] if f != feature_x]
            feature_y = st.selectbox(
                "Seleccione la segunda caracter铆stica (eje Y):",
                remaining_features,
                index=0  # Primera opci贸n disponible
            )
        
        # Funci贸n para crear visualizaci贸n 3D con Plotly
        @st.cache_data
        def create_3d_visualization(data, x1_name, x2_name, y_name):
            # Extraemos los datos
            x1 = data[x1_name]
            x2 = data[x2_name]
            y = data[y_name]
            
            # Ajustamos un modelo de regresi贸n para obtener el plano
            X = data[[x1_name, x2_name]]
            model = LinearRegression()
            model.fit(X, y)
            
            # Creamos una malla para el plano de regresi贸n
            x1_range = np.linspace(x1.min(), x1.max(), 50)
            x2_range = np.linspace(x2.min(), x2.max(), 50)
            x1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)
            
            # Predicciones para la malla
            X_mesh = np.column_stack((x1_mesh.flatten(), x2_mesh.flatten()))
            y_pred = model.predict(X_mesh).reshape(x1_mesh.shape)
            
            # Ecuaci贸n del plano
            intercept = model.intercept_
            coef1 = model.coef_[0]
            coef2 = model.coef_[1]
            equation = f'{y_name} = {coef1:.2f}*{x1_name} + {coef2:.2f}*{x2_name} + {intercept:.2f}'
            r2 = model.score(X, y)
            
            fig = go.Figure() # Creamos la figura de Plotly
            
            # A帽adimos los puntos de datos
            fig.add_trace(
                go.Scatter3d(
                    x=x1,
                    y=x2,
                    z=y,
                    mode='markers',
                    marker=dict(
                        size=5,
                        color=y,
                        colorscale='Viridis',
                        opacity=0.7,
                        colorbar=dict(title=y_name)
                    ),
                    name='Datos'
                )
            )
            
            # A帽adimos el plano de regresi贸n
            fig.add_trace(
                go.Surface(
                    x=x1_mesh,
                    y=x2_mesh,
                    z=y_pred,
                    colorscale='RdBu',
                    opacity=0.7,
                    name='Plano de Regresi贸n',
                    showscale=False
                )
            )
            
            # Configuramos el layout
            fig.update_layout(
                title=f'Relaci贸n 3D: {x1_name} y {x2_name} vs {y_name}',
                scene=dict(
                    xaxis_title=x1_name,
                    yaxis_title=x2_name,
                    zaxis_title=y_name,
                    aspectratio=dict(x=1, y=1, z=0.7)
                ),
                width=800,
                height=700,
                margin=dict(l=0, r=0, b=0, t=40)
            )
            
            # A帽adimos anotaci贸n con la ecuaci贸n
            fig.add_annotation(
                x=0.02,
                y=0.98,
                xref="paper",
                yref="paper",
                text=f"Ecuaci贸n: {equation}<br>R虏 = {r2:.4f}",
                showarrow=False,
                font=dict(size=14),
                bgcolor="white",
                bordercolor="black",
                borderwidth=1,
                borderpad=4,
                align="left"
            )
            
            return fig
        
        # Creamos y mostramos la visualizaci贸n 3D
        fig_3d = create_3d_visualization(data, feature_x, feature_y, 'Performance Index')
        st.plotly_chart(fig_3d, use_container_width=True)
        
        # Visualizaci贸n por categor铆a
        st.subheader("Visualizaci贸n 3D por Actividad Extracurricular")
        
        show_categorical = st.checkbox("Mostrar an谩lisis por actividad extracurricular", value=False)
        
        if show_categorical:
            # Funci贸n para crear visualizaci贸n 3D por categor铆a
            @st.cache_data
            def create_3d_categorical(data, x1_name, x2_name, y_name, cat_name):
                fig = go.Figure()
                
                # Obtener categor铆as 煤nicas
                categories = data[cat_name].unique()
                colors = ['red', 'blue']  # Para Yes/No
                
                equations = []
                
                for i, category in enumerate(categories):
                    # Filtrar datos para esta categor铆a
                    cat_data = data[data[cat_name] == category]
                    
                    # Extraer datos
                    x1 = cat_data[x1_name]
                    x2 = cat_data[x2_name]
                    y = cat_data[y_name]
                    
                    # Ajustar modelo
                    X = cat_data[[x1_name, x2_name]]
                    model = LinearRegression()
                    model.fit(X, y)
                    
                    # Crear malla
                    x1_range = np.linspace(x1.min(), x1.max(), 30)
                    x2_range = np.linspace(x2.min(), x2.max(), 30)
                    x1_mesh, x2_mesh = np.meshgrid(x1_range, x2_range)
                    
                    # Predicciones
                    X_mesh = np.column_stack((x1_mesh.flatten(), x2_mesh.flatten()))
                    y_pred = model.predict(X_mesh).reshape(x1_mesh.shape)
                    
                    # Ecuaci贸n
                    intercept = model.intercept_
                    coef1 = model.coef_[0]
                    coef2 = model.coef_[1]
                    r2 = model.score(X, y)
                    equation = f"{cat_name}={category}: {y_name} = {coef1:.2f}*{x1_name} + {coef2:.2f}*{x2_name} + {intercept:.2f} (R虏={r2:.4f})"
                    equations.append(equation)
                    
                    # A帽adir puntos
                    fig.add_trace(
                        go.Scatter3d(
                            x=x1,
                            y=x2,
                            z=y,
                            mode='markers',
                            marker=dict(
                                size=5,
                                color=colors[i],
                                opacity=0.7
                            ),
                            name=f'{cat_name}={category}'
                        )
                    )
                    
                    # A帽adir plano
                    fig.add_trace(
                        go.Surface(
                            x=x1_mesh,
                            y=x2_mesh,
                            z=y_pred,
                            colorscale=[[0, colors[i]], [1, colors[i]]],
                            opacity=0.4,
                            showscale=False,
                            name=f'Plano ({category})'
                        )
                    )
                
                # Configurar layout
                fig.update_layout(
                    title=f'Efecto de {cat_name} en la relaci贸n entre {x1_name}, {x2_name} y {y_name}',
                    scene=dict(
                        xaxis_title=x1_name,
                        yaxis_title=x2_name,
                        zaxis_title=y_name,
                        aspectratio=dict(x=1, y=1, z=0.7)
                    ),
                    width=800,
                    height=700,
                    margin=dict(l=0, r=0, b=0, t=40)
                )
                
                # A帽adir ecuaciones
                for i, eq in enumerate(equations):
                    fig.add_annotation(
                        x=0.02,
                        y=0.98 - i*0.08,
                        xref="paper",
                        yref="paper",
                        text=eq,
                        showarrow=False,
                        font=dict(size=12, color=colors[i]),
                        bgcolor="white",
                        bordercolor=colors[i],
                        borderwidth=1,
                        borderpad=4,
                        align="left"
                    )
                
                return fig
            
            fig_cat = create_3d_categorical(data, feature_x, feature_y, 'Performance Index', 'Extracurricular Activities')
            st.plotly_chart(fig_cat, use_container_width=True)
            
            st.markdown("""
            <div class='caption'>
            Esta visualizaci贸n muestra c贸mo la participaci贸n en actividades extracurriculares afecta la relaci贸n entre las variables seleccionadas y el rendimiento acad茅mico.
            Los diferentes colores representan las categor铆as (S铆/No) y cada plano muestra la relaci贸n lineal para esa categor铆a espec铆fica.
            </div>
            """, unsafe_allow_html=True)
    
    # 4. MODELADO Y OPTIMIZACIN
    elif pages == "4. Modelado y Optimizaci贸n":
        st.markdown("<h2 class='subtitle'>4. Modelado y Optimizaci贸n</h2>", unsafe_allow_html=True)
        
        # Dividimos la p谩gina en pesta帽as para los diferentes experimentos
        tabs = st.tabs([
            "Proporciones Train/Test", 
            "M茅todos de Optimizaci贸n", 
            "M茅todos de Regularizaci贸n"
        ])
        
        # Preparaci贸n de datos (com煤n para todos los experimentos)
        X = data.drop('Performance Index', axis=1)
        y = data['Performance Index']
        
        # Preprocesamiento para la variable categ贸rica
        preprocessor = ColumnTransformer(
            transformers=[
                ('cat', OneHotEncoder(drop='first'), ['Extracurricular Activities'])
            ],
            remainder='passthrough'
        )
        
        # Pesta帽a 1: Proporciones Train/Test
        with tabs[0]:
            st.subheader("Experimentaci贸n con Diferentes Proporciones Train/Test")
            
            st.write("""
            En esta secci贸n, evaluamos c贸mo diferentes proporciones de datos de entrenamiento y prueba
            afectan el desempe帽o del modelo de regresi贸n lineal.
            """)
            
            # Permitir al usuario seleccionar proporciones
            st.markdown("### Seleccione proporciones a evaluar")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                split1 = st.slider("Proporci贸n 1 (% Train)", 
                                   min_value=10, max_value=90, value=70, step=5)
            with col2:
                split2 = st.slider("Proporci贸n 2 (% Train)", 
                                   min_value=10, max_value=90, value=50, step=5)
            with col3:
                split3 = st.slider("Proporci贸n 3 (% Train)", 
                                   min_value=10, max_value=90, value=40, step=5)
            
            # Bot贸n para ejecutar el experimento
            if st.button("Ejecutar Experimento de Proporciones"):
                # Convertimos los porcentajes a proporciones
                splits = [(split1/100, 1-split1/100), 
                          (split2/100, 1-split2/100), 
                          (split3/100, 1-split3/100)]
                
                results_splits = []
                
                with st.spinner("Ejecutando experimento..."):
                    for train_size, test_size in splits:
                        # Divisi贸n de datos
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=test_size, random_state=42
                        )
                        
                        # Pipeline
                        pipeline = Pipeline([
                            ('preprocessor', preprocessor),
                            ('regressor', LinearRegression())
                        ])
                        
                        # Entrenamiento
                        pipeline.fit(X_train, y_train)
                        
                        # Evaluaci贸n
                        y_pred = pipeline.predict(X_test)
                        mse = mean_squared_error(y_test, y_pred)
                        r2 = r2_score(y_test, y_pred)
                        
                        # Resultados
                        results_splits.append({
                            'Train-Test Split': f"{train_size:.2f}-{test_size:.2f}",
                            'Muestras Train': int(train_size * len(X)),
                            'Muestras Test': int(test_size * len(X)),
                            'MSE': mse,
                            'R虏': r2
                        })
                
                # Mostrar resultados en tabla
                splits_df = pd.DataFrame(results_splits)
                st.subheader("Resultados")
                st.dataframe(splits_df)
                
                # Visualizar resultados
                fig, ax = plt.subplots(1, 2, figsize=(14, 5))
                
                # Gr谩fico de MSE
                sns.barplot(x='Train-Test Split', y='MSE', data=splits_df, ax=ax[0])
                ax[0].set_title('MSE por Proporci贸n Train-Test')
                ax[0].set_ylabel('Mean Squared Error')
                ax[0].set_ylim(bottom=0)
                
                # Gr谩fico de R虏
                sns.barplot(x='Train-Test Split', y='R虏', data=splits_df, ax=ax[1])
                ax[1].set_title('R虏 por Proporci贸n Train-Test')
                ax[1].set_ylabel('R虏 Score')
                ax[1].set_ylim(0, 1)
                
                plt.tight_layout()
                st.pyplot(fig)
                
                # Interpretaci贸n
                st.subheader("Interpretaci贸n")
                
                best_split = splits_df.iloc[splits_df['R虏'].argmax()]
                
                st.markdown(f"""
                - La mejor proporci贸n de train/test seg煤n R虏 es **{best_split['Train-Test Split']}** con R虏={best_split['R虏']:.4f}
                - El MSE m谩s bajo se obtuvo con la proporci贸n **{splits_df.iloc[splits_df['MSE'].argmin()]['Train-Test Split']}** (MSE={splits_df['MSE'].min():.4f})
                - Una proporci贸n adecuada equilibra la cantidad de datos disponibles para entrenar el modelo y la cantidad necesaria para evaluarlo de manera confiable.
                """)
                
                # Guardar el mejor valor para usar en otras pesta帽as
                st.session_state['best_split'] = float(best_split['Train-Test Split'].split('-')[0])
        
        # Pesta帽a 2: M茅todos de Optimizaci贸n
        with tabs[1]:
            st.subheader("Experimentaci贸n con Diferentes M茅todos de Optimizaci贸n")
            
            st.write("""
            En esta secci贸n, evaluamos c贸mo diferentes m茅todos de optimizaci贸n afectan el desempe帽o
            del modelo de regresi贸n lineal. Comparamos la ecuaci贸n normal (m茅todo est谩ndar) con
            diferentes configuraciones del Descenso de Gradiente Estoc谩stico (SGD).
            """)
            
            # Usar la mejor proporci贸n si est谩 disponible, sino usar 0.7 (70%)
            best_split = st.session_state.get('best_split', 0.7)
            
            # Permitir ajustar par谩metros de SGD
            st.markdown("### Configuraci贸n de SGD")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                alpha1 = st.number_input("Alpha 1", 
                                         min_value=0.00001, max_value=1.0, 
                                         value=0.01, format="%.5f", step=0.001)
            with col2:
                alpha2 = st.number_input("Alpha 2", 
                                         min_value=0.00001, max_value=1.0, 
                                         value=0.001, format="%.5f", step=0.0001)
            with col3:
                alpha3 = st.number_input("Alpha 3", 
                                         min_value=0.00001, max_value=1.0, 
                                         value=0.0001, format="%.5f", step=0.00001)
            
            max_iter = st.slider("Iteraciones m谩ximas", 
                                 min_value=100, max_value=10000, value=1000, step=100)
            
            # Bot贸n para ejecutar el experimento
            if st.button("Ejecutar Experimento de Optimizaci贸n"):
                # Divisi贸n de datos
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=(1-best_split), random_state=42
                )
                
                # Definir optimizadores
                optimizers = {
                    'Linear Regression (Normal Equation)': LinearRegression(),
                    f'SGD (alpha={alpha1}, max_iter={max_iter})': SGDRegressor(
                        alpha=alpha1, max_iter=max_iter, random_state=42, learning_rate='constant', eta0=0.01),
                    f'SGD (alpha={alpha2}, max_iter={max_iter})': SGDRegressor(
                        alpha=alpha2, max_iter=max_iter, random_state=42, learning_rate='constant', eta0=0.01),
                    f'SGD (alpha={alpha3}, max_iter={max_iter})': SGDRegressor(
                        alpha=alpha3, max_iter=max_iter, random_state=42, learning_rate='constant', eta0=0.01)
                }
                
                results_optimizers = []
                
                with st.spinner("Ejecutando experimento..."):
                    for name, optimizer in optimizers.items():
                        try:
                            # Pipeline
                            pipeline = Pipeline([
                                ('preprocessor', preprocessor),
                                ('regressor', optimizer)
                            ])
                            
                            # Entrenamiento
                            pipeline.fit(X_train, y_train)
                            
                            # Evaluaci贸n
                            y_pred = pipeline.predict(X_test)
                            mse = mean_squared_error(y_test, y_pred)
                            r2 = r2_score(y_test, y_pred)
                            
                            # Resultados
                            results_optimizers.append({
                                'Optimizer': name,
                                'MSE': mse,
                                'R虏': r2
                            })
                        except Exception as e:
                            results_optimizers.append({
                                'Optimizer': name,
                                'MSE': 'Error',
                                'R虏': 'Error',
                                'Error': str(e)
                            })
                
                # Mostrar resultados en tabla
                optimizers_df = pd.DataFrame(results_optimizers)
                st.subheader("Resultados")
                st.dataframe(optimizers_df)
                
                # Filtrar resultados con errores
                valid_results = optimizers_df[optimizers_df['MSE'] != 'Error'].copy()
                
                if not valid_results.empty:
                    # Convertir a num茅rico para visualizaci贸n
                    valid_results['MSE'] = pd.to_numeric(valid_results['MSE'])
                    valid_results['R虏'] = pd.to_numeric(valid_results['R虏'])
                    
                    # Visualizar resultados
                    fig, ax = plt.subplots(1, 2, figsize=(14, 5))
                    
                    # Gr谩fico de MSE
                    sns.barplot(x='Optimizer', y='MSE', data=valid_results, ax=ax[0])
                    ax[0].set_title('MSE por M茅todo de Optimizaci贸n')
                    ax[0].set_ylabel('Mean Squared Error')
                    ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, ha='right')
                    ax[0].set_ylim(bottom=0)
                    
                    # Gr谩fico de R虏
                    sns.barplot(x='Optimizer', y='R虏', data=valid_results, ax=ax[1])
                    ax[1].set_title('R虏 por M茅todo de Optimizaci贸n')
                    ax[1].set_ylabel('R虏 Score')
                    ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, ha='right')
                    ax[1].set_ylim(0, 1)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                
                # Interpretaci贸n
                st.subheader("Interpretaci贸n")
                
                if 'Error' in optimizers_df['MSE'].values:
                    st.warning("Algunos m茅todos de optimizaci贸n generaron errores. Intente con diferentes valores de alpha o iteraciones.")
                
                if not valid_results.empty:
                    best_opt = valid_results.iloc[valid_results['R虏'].argmax()]
                    
                    st.markdown(f"""
                    - El mejor m茅todo de optimizaci贸n seg煤n R虏 es **{best_opt['Optimizer']}** con R虏={best_opt['R虏']:.4f}
                    - El MSE m谩s bajo se obtuvo con **{valid_results.iloc[valid_results['MSE'].argmin()]['Optimizer']}** (MSE={valid_results['MSE'].min():.4f})
                    - La regresi贸n lineal est谩ndar (ecuaci贸n normal) y el SGD pueden tener diferentes comportamientos dependiendo de los par谩metros y la naturaleza de los datos.
                    """)
                    
                    # Guardar el mejor optimizador para usar en otras pesta帽as
                    st.session_state['best_optimizer'] = best_opt['Optimizer']
                else:
                    st.error("No se obtuvieron resultados v谩lidos. Intente con diferentes par谩metros.")
        
        # Pesta帽a 3: M茅todos de Regularizaci贸n
        with tabs[2]:
            st.subheader("Experimentaci贸n con Diferentes M茅todos de Regularizaci贸n")
            
            st.write("""
            En esta secci贸n, evaluamos c贸mo diferentes m茅todos de regularizaci贸n afectan el desempe帽o
            del modelo de regresi贸n lineal. Comparamos el modelo sin regularizaci贸n con Ridge (L2),
            Lasso (L1) y ElasticNet (combinaci贸n de L1 y L2).
            """)
            
            # Usar la mejor proporci贸n si est谩 disponible, sino usar 0.7 (70%)
            best_split = st.session_state.get('best_split', 0.7)
            
            # Permitir ajustar par谩metros de regularizaci贸n
            st.markdown("### Configuraci贸n de Regularizaci贸n")
            
            col1, col2 = st.columns(2)
            
            with col1:
                alpha_high = st.number_input("Alpha (alto)", 
                                            min_value=0.01, max_value=10.0, 
                                            value=1.0, format="%.2f", step=0.1)
            with col2:
                alpha_low = st.number_input("Alpha (bajo)", 
                                           min_value=0.001, max_value=1.0, 
                                           value=0.1, format="%.3f", step=0.01)
            
            l1_ratio = st.slider("L1 Ratio (para ElasticNet)", 
                                min_value=0.0, max_value=1.0, value=0.5, step=0.1)
            
            # Bot贸n para ejecutar el experimento
            if st.button("Ejecutar Experimento de Regularizaci贸n"):
                # Divisi贸n de datos
                X_train, X_test, y_train, y_test = train_test_split(
                    X, y, test_size=(1-best_split), random_state=42
                )
                
                # Definir regularizadores
                regularizers = {
                    'No Regularization': LinearRegression(),
                    f'Ridge (alpha={alpha_high})': Ridge(alpha=alpha_high, random_state=42),
                    f'Ridge (alpha={alpha_low})': Ridge(alpha=alpha_low, random_state=42),
                    f'Lasso (alpha={alpha_high})': Lasso(alpha=alpha_high, random_state=42),
                    f'Lasso (alpha={alpha_low})': Lasso(alpha=alpha_low, random_state=42),
                    f'ElasticNet (alpha={alpha_high}, l1_ratio={l1_ratio})': ElasticNet(
                        alpha=alpha_high, l1_ratio=l1_ratio, random_state=42),
                    f'ElasticNet (alpha={alpha_low}, l1_ratio={l1_ratio})': ElasticNet(
                        alpha=alpha_low, l1_ratio=l1_ratio, random_state=42)
                }
                
                results_regularizers = []
                
                with st.spinner("Ejecutando experimento..."):
                    for name, regularizer in regularizers.items():
                        try:
                            # Pipeline
                            pipeline = Pipeline([
                                ('preprocessor', preprocessor),
                                ('regressor', regularizer)
                            ])
                            
                            # Entrenamiento
                            pipeline.fit(X_train, y_train)
                            
                            # Evaluaci贸n
                            y_pred = pipeline.predict(X_test)
                            mse = mean_squared_error(y_test, y_pred)
                            r2 = r2_score(y_test, y_pred)
                            
                            # Resultados
                            results_regularizers.append({
                                'Regularizer': name,
                                'MSE': mse,
                                'R虏': r2
                            })
                        except Exception as e:
                            results_regularizers.append({
                                'Regularizer': name,
                                'MSE': 'Error',
                                'R虏': 'Error',
                                'Error': str(e)
                            })
                
                # Mostrar resultados en tabla
                regularizers_df = pd.DataFrame(results_regularizers)
                st.subheader("Resultados")
                st.dataframe(regularizers_df)
                
                # Filtrar resultados con errores
                valid_results = regularizers_df[regularizers_df['MSE'] != 'Error'].copy()
                
                if not valid_results.empty:
                    # Convertir a num茅rico para visualizaci贸n
                    valid_results['MSE'] = pd.to_numeric(valid_results['MSE'])
                    valid_results['R虏'] = pd.to_numeric(valid_results['R虏'])
                    
                    # Visualizar resultados
                    fig, ax = plt.subplots(1, 2, figsize=(14, 5))
                    
                    # Gr谩fico de MSE
                    sns.barplot(x='Regularizer', y='MSE', data=valid_results, ax=ax[0])
                    ax[0].set_title('MSE por M茅todo de Regularizaci贸n')
                    ax[0].set_ylabel('Mean Squared Error')
                    ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=45, ha='right')
                    ax[0].set_ylim(bottom=0)
                    
                    # Gr谩fico de R虏
                    sns.barplot(x='Regularizer', y='R虏', data=valid_results, ax=ax[1])
                    ax[1].set_title('R虏 por M茅todo de Regularizaci贸n')
                    ax[1].set_ylabel('R虏 Score')
                    ax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=45, ha='right')
                    ax[1].set_ylim(0, 1)
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                
                # Interpretaci贸n
                st.subheader("Interpretaci贸n")
                
                if not valid_results.empty:
                    best_reg = valid_results.iloc[valid_results['R虏'].argmax()]
                    
                    st.markdown(f"""
                    - El mejor m茅todo de regularizaci贸n seg煤n R虏 es **{best_reg['Regularizer']}** con R虏={best_reg['R虏']:.4f}
                    - El MSE m谩s bajo se obtuvo con **{valid_results.iloc[valid_results['MSE'].argmin()]['Regularizer']}** (MSE={valid_results['MSE'].min():.4f})
                    - La regularizaci贸n puede ayudar a prevenir el sobreajuste penalizando la magnitud de los coeficientes.
                    - Ridge (L2) penaliza el cuadrado de los coeficientes, reduciendo su magnitud pero sin llevarlos a cero.
                    - Lasso (L1) puede llevar coeficientes a cero, actuando como selector de caracter铆sticas.
                    - ElasticNet combina ambos enfoques, ofreciendo un equilibrio entre reducci贸n y selecci贸n.
                    """)
                    
                    # Guardar el mejor regularizador para usar en otras pesta帽as
                    st.session_state['best_regularizer'] = best_reg['Regularizer']
                else:
                    st.error("No se obtuvieron resultados v谩lidos. Intente con diferentes par谩metros.")
    
    # 5. MTRICAS Y EVALUACIN
    elif pages == "5. M茅tricas y Evaluaci贸n":
        st.markdown("<h2 class='subtitle'>5. M茅tricas y Evaluaci贸n del Modelo Final</h2>", unsafe_allow_html=True)
        
        # Verificar si tenemos los mejores par谩metros de los experimentos anteriores
        best_split = st.session_state.get('best_split', 0.7)
        best_regularizer = st.session_state.get('best_regularizer', 'Ridge (alpha=0.1)')
        
        st.write(f"""
        En esta secci贸n, analizamos el modelo final utilizando los mejores par谩metros 
        encontrados en los experimentos anteriores:
        - Proporci贸n de train/test: {best_split:.2f}-{1-best_split:.2f}
        - M茅todo de regularizaci贸n: {best_regularizer}
        """)
        
        # Configuraci贸n del modelo final
        st.subheader("Configuraci贸n del Modelo Final")
        
        # Permitir ajustes finales
        use_best_params = st.checkbox("Usar los mejores par谩metros de los experimentos anteriores", value=True)
        
        if use_best_params:
            split = best_split # Usar los mejores par谩metros encontrados
            
            # Determinar el regularizador basado en el nombre
            if 'Ridge' in best_regularizer:
                alpha = float(best_regularizer.split('alpha=')[1].split(')')[0])
                regularizer = Ridge(alpha=alpha, random_state=42)
                regularizer_name = f'Ridge (alpha={alpha})'
            elif 'Lasso' in best_regularizer:
                alpha = float(best_regularizer.split('alpha=')[1].split(')')[0])
                regularizer = Lasso(alpha=alpha, random_state=42)
                regularizer_name = f'Lasso (alpha={alpha})'
            elif 'ElasticNet' in best_regularizer:
                alpha = float(best_regularizer.split('alpha=')[1].split(',')[0])
                l1_ratio = float(best_regularizer.split('l1_ratio=')[1].split(')')[0])
                regularizer = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
                regularizer_name = f'ElasticNet (alpha={alpha}, l1_ratio={l1_ratio})'
            else:
                regularizer = LinearRegression()
                regularizer_name = 'Linear Regression (No Regularization)'
        else:
            # Permitir al usuario configurar manualmente
            col1, col2 = st.columns(2)
            
            with col1:
                split = st.slider("Proporci贸n de entrenamiento", 
                                 min_value=0.1, max_value=0.9, value=0.7, step=0.05)
            
            with col2:
                reg_method = st.selectbox("M茅todo de regularizaci贸n", 
                                        ['Sin regularizaci贸n', 'Ridge', 'Lasso', 'ElasticNet'])
            
            if reg_method != 'Sin regularizaci贸n':
                alpha = st.number_input("Alpha", 
                                        min_value=0.001, max_value=10.0, 
                                        value=0.1, format="%.3f", step=0.01)
                
                if reg_method == 'ElasticNet':
                    l1_ratio = st.slider("L1 Ratio", 
                                        min_value=0.0, max_value=1.0, value=0.5, step=0.1)
                    regularizer = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)
                    regularizer_name = f'ElasticNet (alpha={alpha}, l1_ratio={l1_ratio})'
                elif reg_method == 'Ridge':
                    regularizer = Ridge(alpha=alpha, random_state=42)
                    regularizer_name = f'Ridge (alpha={alpha})'
                else:  # Lasso
                    regularizer = Lasso(alpha=alpha, random_state=42)
                    regularizer_name = f'Lasso (alpha={alpha})'
            else:
                regularizer = LinearRegression()
                regularizer_name = 'Linear Regression (No Regularization)'
        
        # Bot贸n para ejecutar el an谩lisis del modelo final
        if st.button("Analizar Modelo Final"):
            # Preparaci贸n de datos
            X = data.drop('Performance Index', axis=1)
            y = data['Performance Index']
            
            # Preprocesamiento
            preprocessor = ColumnTransformer(
                transformers=[
                    ('cat', OneHotEncoder(drop='first'), ['Extracurricular Activities'])
                ],
                remainder='passthrough'
            )
            
            # Divisi贸n de datos
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=(1-split), random_state=42
            )
            
            with st.spinner("Entrenando el modelo final..."):
                # Pipeline
                best_model = Pipeline([
                    ('preprocessor', preprocessor),
                    ('regressor', regularizer)
                ])
                
                # Entrenamiento
                best_model.fit(X_train, y_train)
                
                # Evaluaci贸n
                y_pred = best_model.predict(X_test)
                final_mse = mean_squared_error(y_test, y_pred)
                final_r2 = r2_score(y_test, y_pred)
            
            # Mostrar m茅tricas finales
            st.subheader("M茅tricas del Modelo Final")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Mean Squared Error (MSE)", f"{final_mse:.4f}")
            
            with col2:
                st.metric("R虏 Score", f"{final_r2:.4f}")
            
            # Visualizar predicciones vs valores reales
            st.subheader("Predicciones vs Valores Reales")
            
            fig = px.scatter(
                x=y_test, y=y_pred,
                labels={'x': 'Valores Reales', 'y': 'Predicciones'},
                title='Predicciones vs Valores Reales'
            )
            
            # A帽adir l铆nea de referencia perfecta
            fig.add_trace(
                go.Scatter(
                    x=[y_test.min(), y_test.max()],
                    y=[y_test.min(), y_test.max()],
                    mode='lines',
                    line=dict(color='red', dash='dash'),
                    name='Predicci贸n Perfecta'
                )
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Visualizar residuos
            st.subheader("An谩lisis de Residuos")
            
            residuals = y_test - y_pred
            
            fig_res = px.scatter(
                x=y_pred, y=residuals,
                labels={'x': 'Predicciones', 'y': 'Residuos'},
                title='Gr谩fico de Residuos'
            )
            
            fig_res.add_hline(
                y=0, line_dash="dash", line_color="red",
                annotation_text="Residuo cero",
                annotation_position="bottom right"
            )
            
            st.plotly_chart(fig_res, use_container_width=True)
            
            # Histograma de residuos
            fig_hist = px.histogram(
                residuals, nbins=30,
                labels={'value': 'Residuos'},
                title='Distribuci贸n de Residuos'
            )
            
            st.plotly_chart(fig_hist, use_container_width=True)
            
            # An谩lisis de coeficientes
            st.subheader("An谩lisis de Coeficientes")
            
            try:
                # Obtener nombres de caracter铆sticas
                feature_names = list(best_model.named_steps['preprocessor'].transformers_[0][1].get_feature_names_out(['Extracurricular Activities']))
                feature_names.extend(['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced'])
                
                # Obtener coeficientes
                coefficients = best_model.named_steps['regressor'].coef_
                intercept = best_model.named_steps['regressor'].intercept_
                
                # Crear DataFrame para visualizaci贸n
                coef_df = pd.DataFrame({
                    'Feature': feature_names,
                    'Coefficient': coefficients
                })
                coef_df = coef_df.sort_values('Coefficient', ascending=False)
                
                # Mostrar intercepci贸n
                st.write(f"**Intercepci贸n (valor base):** {intercept:.4f}")
                
                # Visualizar coeficientes
                fig_coef = px.bar(
                    coef_df,
                    x='Coefficient', y='Feature',
                    orientation='h',
                    title='Coeficientes del Modelo Final',
                    labels={'Coefficient': 'Valor del Coeficiente', 'Feature': 'Caracter铆stica'}
                )
                
                fig_coef.add_vline(
                    x=0, line_dash="dash", line_color="black",
                    annotation_text="Cero",
                    annotation_position="top"
                )
                
                st.plotly_chart(fig_coef, use_container_width=True)
                
                # Interpretaci贸n de coeficientes
                st.subheader("Interpretaci贸n de Coeficientes")
                
                st.markdown("""
                #### Significado de la magnitud y signo de los coeficientes:
                
                - **Magnitud**: Indica la importancia relativa de cada caracter铆stica.
                  Un coeficiente mayor (en valor absoluto) tiene un mayor impacto en la predicci贸n.
                
                - **Signo**: Indica la direcci贸n de la relaci贸n con la variable dependiente.
                  - Positivo: Al aumentar la caracter铆stica, aumenta el Performance Index.
                  - Negativo: Al aumentar la caracter铆stica, disminuye el Performance Index.
                """)
                
                # An谩lisis detallado de los coeficientes principales
                top_positive = coef_df[coef_df['Coefficient'] > 0].head(3)
                top_negative = coef_df[coef_df['Coefficient'] < 0].head(3)
                
                if not top_positive.empty:
                    st.markdown("#### Caracter铆sticas con mayor impacto positivo:")
                    for _, row in top_positive.iterrows():
                        st.markdown(f"- **{row['Feature']}** (coef: {row['Coefficient']:.4f}): Por cada unidad de aumento en {row['Feature']}, el Performance Index aumenta en {row['Coefficient']:.4f} unidades, manteniendo las dem谩s variables constantes.")
                
                if not top_negative.empty:
                    st.markdown("#### Caracter铆sticas con mayor impacto negativo:")
                    for _, row in top_negative.iterrows():
                        st.markdown(f"- **{row['Feature']}** (coef: {row['Coefficient']:.4f}): Por cada unidad de aumento en {row['Feature']}, el Performance Index disminuye en {abs(row['Coefficient']):.4f} unidades, manteniendo las dem谩s variables constantes.")
            
            except Exception as e:
                st.error(f"Error al analizar coeficientes: {str(e)}")
            
            # Interpretaci贸n de m茅tricas
            st.subheader("Interpretaci贸n de M茅tricas")
            
            st.markdown(f"""
            #### Mean Squared Error (MSE): {final_mse:.4f}
            - Mide el promedio de los errores al cuadrado entre las predicciones y los valores reales.
            - Un valor m谩s bajo indica un mejor ajuste del modelo.
            - En este caso, el error cuadr谩tico medio es de {final_mse:.4f}, lo que significa que, en promedio, 
              nuestras predicciones tienen un error de aproximadamente {np.sqrt(final_mse):.4f} unidades de Performance Index.
            
            #### R虏 Score: {final_r2:.4f}
            - Indica la proporci贸n de la varianza en la variable dependiente que es predecible a partir de las variables independientes.
            - R虏 = 1: Ajuste perfecto
            - R虏 = 0: El modelo no explica nada de la variabilidad
            - R虏 < 0: El modelo es peor que predecir la media
            - En este caso, nuestro modelo explica aproximadamente el {final_r2*100:.2f}% de la variabilidad en el rendimiento acad茅mico,
              lo que indica un {final_r2 > 0.9 and "excelente" or final_r2 > 0.7 and "buen" or "moderado"} ajuste a los datos.
            """)
    
    # 6. CONCLUSIONES
    elif pages == "6. Conclusiones":
        st.markdown("<h2 class='subtitle'>6. Conclusiones</h2>", unsafe_allow_html=True)
        
        # Verificar si tenemos los mejores par谩metros de los experimentos anteriores
        best_split = st.session_state.get('best_split', 0.7)
        best_regularizer = st.session_state.get('best_regularizer', 'Ridge (alpha=0.1)')
        best_r2 = st.session_state.get('best_r2', 0.989)
        
        st.markdown("""
        A partir del an谩lisis realizado, podemos extraer las siguientes conclusiones:
        """)
        
        # Conclusiones sobre el dataset
        st.subheader("Sobre el Dataset")
        st.markdown("""
        - El dataset de rendimiento estudiantil contiene 10,000 muestras y 6 variables, incluyendo 5 predictores y 1 variable objetivo.
        - La variable dependiente "Performance Index" representa el rendimiento acad茅mico de los estudiantes.
        - Las principales variables predictoras incluyen horas de estudio, calificaciones previas, actividades extracurriculares, horas de sue帽o y ex谩menes de pr谩ctica.
        """)
        
        # Conclusiones sobre las relaciones entre variables
        st.subheader("Sobre las Relaciones entre Variables")
        st.markdown("""
        - **Previous Scores** muestra la correlaci贸n m谩s fuerte con el rendimiento acad茅mico (r  0.915), indicando que el rendimiento pasado es un fuerte predictor del rendimiento futuro.
        - **Hours Studied** tiene una correlaci贸n moderada (r  0.374), demostrando que el tiempo dedicado al estudio influye significativamente en el rendimiento.
        - **Sleep Hours** presenta una correlaci贸n d茅bil pero positiva (r  0.048), sugiriendo que las horas de sue帽o tienen un impacto menor pero existente.
        - La participaci贸n en **Extracurricular Activities** muestra un efecto positivo en el rendimiento acad茅mico, lo que podr铆a indicar beneficios de desarrollo integral.
        """)
        
        # Conclusiones sobre el modelado
        st.subheader("Sobre el Modelado y Optimizaci贸n")
        st.markdown(f"""
        - La proporci贸n 贸ptima de train/test fue {best_split:.2f}-{1-best_split:.2f}, balanceando adecuadamente el tama帽o del conjunto de entrenamiento con la necesidad de una evaluaci贸n confiable.
        - El m茅todo de optimizaci贸n m谩s efectivo fue la Regresi贸n Lineal con Ecuaci贸n Normal, superando significativamente al Descenso de Gradiente Estoc谩stico (SGD) en este problema espec铆fico.
        - La regularizaci贸n {best_regularizer} result贸 ser la m谩s adecuada, indicando que el modelo no sufr铆a de sobreajuste significativo.
        - El modelo final logra explicar aproximadamente un {best_r2*100:.1f}% de la variabilidad en el rendimiento acad茅mico, demostrando un ajuste excelente.
        """)
        
        # Conclusiones sobre los coeficientes
        st.subheader("Sobre los Coeficientes del Modelo")
        st.markdown("""
        - **Previous Scores** tiene el mayor impacto en t茅rminos de correlaci贸n, pero **Hours Studied** tiene el coeficiente m谩s alto, indicando que cada hora adicional de estudio contribuye significativamente al rendimiento.
        - Todos los predictores mostraron coeficientes positivos, indicando que cada uno contribuye positivamente al rendimiento acad茅mico.
        - La participaci贸n en actividades extracurriculares tiene un efecto positivo moderado, sugiriendo beneficios que complementan el estudio acad茅mico tradicional.
        """)
        
        # Conclusiones generales y aplicaciones
        st.subheader("Conclusiones Generales")
        st.markdown("""
        - Los algoritmos de optimizaci贸n pueden tener rendimientos muy diferentes dependiendo de la naturaleza de los datos y el problema.
        - La regularizaci贸n es una herramienta valiosa, pero su impacto depende del problema espec铆fico y la calidad de los datos.
        - Este modelo podr铆a ser utilizado por instituciones educativas para:
          - Identificar factores clave que influyen en el rendimiento acad茅mico
          - Desarrollar intervenciones tempranas para estudiantes en riesgo
          - Proporcionar recomendaciones personalizadas para mejorar el rendimiento
        
        Este estudio subraya la importancia de seleccionar cuidadosamente los algoritmos de optimizaci贸n y ajustar sus par谩metros para obtener el mejor rendimiento en aplicaciones de machine learning.
        """)
        
        # Informaci贸n del equipo
        st.markdown("<hr>", unsafe_allow_html=True)
        st.subheader("Informaci贸n del Equipo")
        
        # Permitir ingresar informaci贸n del equipo
        # num_members = st.number_input("N煤mero de integrantes:", min_value=1, max_value=4, value=1, step=1)
        num_members = 3
        st.markdown("### Integrantes")
        lista_integrantes = [
            ["Flavio Arregoces", "200182105"],
            ["Jorge Sanchez", "Pendiente"],
            ["Cristian Gonzales", "200182438"],
        ]

        for i in range(num_members):
            col1, col2 = st.columns(2)
            with col1:
                st.text_input(f"Nombre del integrante {i+1}:", key=f"name_{i}", value=lista_integrantes[i][0], )
            with col2:
                st.text_input(f"C贸digo del integrante {i+1}:", key=f"code_{i}", value=lista_integrantes[i][1], )
        
        # A帽adir fecha y curso
        st.text_input("Curso:", value="Optimizaci贸n",disabled=False)
        st.date_input("Fecha de entrega:", value=pd.to_datetime("2025-05-01"), disabled=False)
else:
    st.error("No se pudo cargar el dataset. Por favor, verifica que el archivo 'Student_Performance.csv' est茅 disponible.")